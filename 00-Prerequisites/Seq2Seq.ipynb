{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b374fd47-efdb-4a51-baf8-5c159af6cafb",
   "metadata": {},
   "source": [
    "# Encoding, Decoding, and Learning: The Math of Seq2Seq Translation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3019d63-91a3-4404-85ca-17192d598227",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this post, you‚Äôll learn the **mathematical foundations of sequence-to-sequence models** for machine translation üåç. We‚Äôll focus on a type of neural network called the **RNN Encoder‚ÄìDecoder**, which is made up of two parts:\n",
    "\n",
    "- üß† An **encoder RNN** that takes a variable-length input sequence and turns it into a fixed-length vector.\n",
    "- üßæ A **decoder RNN** that takes this vector and generates a variable-length output sequence.\n",
    "\n",
    "The model is trained to **predict the target sequence given the input** üéØ, by learning the conditional probability of the output based on the input. \n",
    "\n",
    "As an example, we‚Äôll see how this model can be trained to translate English phrases into French üá¨üáß‚û°Ô∏èüá´üá∑."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adde301-40d4-45e9-87cd-f51fc1b61ad7",
   "metadata": {},
   "source": [
    ":::{tip} Preliminary: Recurrent Neural Networks\n",
    "\n",
    "![](../images/RNN.png)\n",
    "**Figure 1**: RNN (Image by the author).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The input $x_t$\n",
    "In a Recurrent Neural Network (RNN), the input at time step $t$, denoted as $x_t$, represents the data fed into the network at that point in the sequence. It is typically a vector (e.g., a word embedding) in $\\mathbb{R}^d$, where $d$ is the embedding dimension.\n",
    "\n",
    "\n",
    "\n",
    "##### Example: A 4-Word Sentence\n",
    "\n",
    "Consider the sentence:\n",
    "\n",
    "$$\n",
    "\\text{``Cryptocurrency is the future''}\n",
    "$$\n",
    "\n",
    "This sequence has length $m = 4$. The corresponding inputs are:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "x_1 &= \\text{embedding}(\\text{``Cryptocurrency''}) \\\\\n",
    "x_2 &= \\text{embedding}(\\text{``is''}) \\\\\n",
    "x_3 &= \\text{embedding}(\\text{``the''}) \\\\\n",
    "x_4 &= \\text{embedding}(\\text{``future''})\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "## Hidden State $h_t$\n",
    "\n",
    "The hidden state serves as the network's internal memory, encoding contextual information from the sequence up to time $t$. It is updated as shown above, and plays a key role in maintaining temporal dependencies.At each time step, the hidden state $h_t$ is updated based on the current input $x_t$ and the previous hidden state $h_{t-1}$:\n",
    "\n",
    "$$\n",
    "h_t = f(W_{hh} h_{t-1} + W_{xh} x_t + b_h)\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $W_{xh}$ and $W_{hh}$ are weight matrices,\n",
    "- $b_h$ is a bias vector,\n",
    "- $f$ is a nonlinear activation function such as $\\tanh$ or ReLU.\n",
    "\n",
    "## Initial Hidden State $h_0$\n",
    "\n",
    "The initial hidden state $h_0$ represents the starting memory of the RNN before any input is processed. It is typically initialized in one of the following ways:\n",
    "\n",
    "- As a zero vector:  \n",
    "  $\n",
    "  h_0 = \\mathbf{0} \\in \\mathbb{R}^n\n",
    "  $\n",
    "  where $n$ is the dimensionality of the hidden state.\n",
    "\n",
    "- With small random values (e.g., sampled from a normal distribution):  \n",
    "  $\n",
    "  h_0 \\sim \\mathcal{N}(0, \\sigma^2 I)\n",
    "  $\n",
    "\n",
    "- As a learned parameter:  \n",
    "  $h_0$ can also be treated as a trainable vector that is learned during training, allowing the model to adapt its initial memory based on the data.\n",
    "\n",
    "The choice depends on the specific task, model design, and desired behavior at the start of the sequence.\n",
    "\n",
    "\n",
    "## Output $y_t$\n",
    "\n",
    "The output at time step $t$ is computed from the hidden state:\n",
    "\n",
    "$$\n",
    "y_t = g(W_{hy} h_t + b_y)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $W_{hy}$ is the output weight matrix,\n",
    "- $b_y$ is a bias vector,\n",
    "- $g$ is an activation function such as softmax or sigmoid, depending on the task.\n",
    "\n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74820516-0d8a-4648-8124-977a9ecccb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13483830-db93-4f7a-a5fa-f92627189ed5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95e1a5-2c13-4275-bb4d-c9119357d630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4847e8-4047-4d41-9bf8-79d589dc2223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9bb6c-cfb5-4f29-b183-d54f6c861949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d43da-f19b-4f00-901a-b22db6d1a249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd34f7-b962-41ad-b6b8-cbf863aa3ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958050bd-404f-4c83-8a04-d81e6e852f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431326a-93e0-40c5-98d1-b443a04c18a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f6911-380d-45f0-a205-7ec3cf7e703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bd72c-49f6-4bd6-82bd-ef4c63401d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b25ef-8789-4110-b7f4-7d657d2febed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a2f46-2fa9-403a-9b08-7835dddeaed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758a08b-284c-480d-b0a4-6fb88bfca77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc01b30-eb6d-4f09-bb6c-aa4b6471a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3038ef-b850-43d7-a5d2-0a01aa5e6c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cf3f4-0ea9-4d7a-a8a6-8f9dccd39924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391014e7-3db1-4862-9f53-c2e5a796e8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1987dd4-6218-421c-b269-d5c7e1b48859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
